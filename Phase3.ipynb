{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Shiva Radmanesh - clustering",
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sBgVuhKDebV"
      },
      "source": [
        "# **Clustering project (phase 3)**\n",
        "**Contributers:** *Shiva Radmanesh*\n",
        "\n",
        "\\\\"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JBbo3jzf4ud"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qj0Xpx1HzmQt"
      },
      "source": [
        "!unrar e /content/drive/'My Drive'/DataMining/dataset.rar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kx6hgPbh27bM"
      },
      "source": [
        "import pandas as pd \n",
        "print('done')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHh8n6AG08VV"
      },
      "source": [
        "\\\\\n",
        "#**Part 1 - popularity of the products**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2xKTjqf4Nt1c"
      },
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1CQQ5hay4Cc7"
      },
      "source": [
        "### make the item-Quantity dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj160Ehd1Cus"
      },
      "source": [
        "df_orders = pd.read_csv('orders.csv')\n",
        "df_orders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSi4L6rf1I2K"
      },
      "source": [
        "groupedby_item = df_orders.groupby(by=['ID_Item'], as_index=False).sum()\n",
        "item_quantity = groupedby_item.filter(['ID_Item', 'Quantity_item'], axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LkpOJn1g2BeS"
      },
      "source": [
        "item_quantity = item_quantity.sort_values(by=['Quantity_item'] ,ascending=False)\n",
        "\n",
        "item_quantity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T1xNGua-4LsK"
      },
      "source": [
        "\\\\\n",
        "### Make the item-likeScore dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LnIlN3cO394v"
      },
      "source": [
        "df_keifiat = pd.read_excel('keifiat.xlsx')\n",
        "df_keifiat"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SP7eC6L64ohv"
      },
      "source": [
        "item_likes_dislikes = df_keifiat.filter(['product_id','likes', 'dislikes'], axis=1)\n",
        "keifiat_grouped = item_likes_dislikes.groupby(by=['product_id'], as_index=False).sum()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yUWnPh-c4k5r"
      },
      "source": [
        "keifiat_grouped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqMIgqDp6smq"
      },
      "source": [
        "keifiat_grouped.columns = [\"ID_Item\", \"likes\", \"dislikes\"]\n",
        "\n",
        "keifiat_grouped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X3PcKAixSXF"
      },
      "source": [
        "keifiat_grouped['like_score'] = keifiat_grouped.apply(lambda row: (row.likes + 1) / (row.dislikes + 1), axis=1)\n",
        "\n",
        "keifiat_grouped"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONbnvQ7ZCecx"
      },
      "source": [
        "\\\\\n",
        "### combining the previous dataframe to have one dataframe of all needed data\n",
        "In the code cell below, the two dataframe (item_quantity, keifiat_grouped) are being joined together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmhaiIv7CzII"
      },
      "source": [
        "quality_df = item_quantity.join(keifiat_grouped.set_index('ID_Item'), on='ID_Item')\n",
        "\n",
        "quality_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsJSCAKyMflG"
      },
      "source": [
        "\\\\\n",
        "**We have 2 approches:**\n",
        "1. with rows which have NaN values\n",
        "2. without rows which have NaN values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R3-rfF2VM0sN"
      },
      "source": [
        "\\\\\n",
        "fill cells which have NaN values with 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WbUnS65PMjKd"
      },
      "source": [
        "quality_df_with_NaN = quality_df.fillna(0)\n",
        "\n",
        "quality_df_with_NaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ely1UVRXVNh4"
      },
      "source": [
        "quality_df_with_NaN = quality_df_with_NaN.filter(['Quantity_item', 'likes', 'dislikes', 'like_score', 'like_score'], axis=1)\n",
        "\n",
        "quality_df_with_NaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ULZVZgtKNJbi"
      },
      "source": [
        "\\\\\n",
        "drop cells which have NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWruntaWNJcA"
      },
      "source": [
        "quality_df_without_NaN = quality_df.dropna()\n",
        "\n",
        "quality_df_without_NaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCAV85grWf-U"
      },
      "source": [
        "quality_df_without_NaN = quality_df_without_NaN.filter(['Quantity_item', 'likes', 'dislikes', 'like_score'], axis=1)\n",
        "\n",
        "quality_df_without_NaN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhzmuMOBOHNL"
      },
      "source": [
        "## **Clustering**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yPSelHtRUIQ5"
      },
      "source": [
        "### Without NaN values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a03oe3bAUdjO"
      },
      "source": [
        "Agglomerative Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TV5JoTfmUNIT"
      },
      "source": [
        "# agglomerative clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X = quality_df_without_NaN.to_numpy()\n",
        "model = AgglomerativeClustering(n_clusters=4)\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 3])\n",
        "# show the plot\n",
        "\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpdZ3ccvz9So"
      },
      "source": [
        "\\\\\n",
        "DBSCAN Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2BzdH5nk0Gb7"
      },
      "source": [
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.cluster import DBSCAN\n",
        "from matplotlib import pyplot\n",
        "\n",
        "X = quality_df_without_NaN.to_numpy()\n",
        "model = DBSCAN(eps=0.1, min_samples=20)\n",
        "yhat = model.fit_predict(X)\n",
        "clusters = unique(yhat)\n",
        "for cluster in clusters:\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 3])\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1RK2QaJ0nkD"
      },
      "source": [
        "\\\\\n",
        "KMeans Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f4tkOBnl0p-L"
      },
      "source": [
        "# k-means clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.cluster import KMeans\n",
        "from matplotlib import pyplot\n",
        "\n",
        "X = quality_df_without_NaN.to_numpy()\n",
        "model = KMeans(n_clusters=3)\n",
        "model.fit(X)\n",
        "yhat = model.predict(X)\n",
        "clusters = unique(yhat)\n",
        "for cluster in clusters:\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 3])\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VK3MSqDd1AD9"
      },
      "source": [
        "\\\\\n",
        "Mini-batch KMeans clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bgWZ5ibl1F5M"
      },
      "source": [
        "# mini-batch k-means clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.cluster import MiniBatchKMeans\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X = quality_df_without_NaN.to_numpy()\n",
        "# define the model\n",
        "model = MiniBatchKMeans(n_clusters=4)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 3])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IiVBDFjw1TpH"
      },
      "source": [
        "\\\\\n",
        "Mean shift clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kppkpC2w1WWC"
      },
      "source": [
        "\n",
        "# mean shift clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.cluster import MeanShift\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X = quality_df_without_NaN.to_numpy()\n",
        "# define the model\n",
        "model = MeanShift()\n",
        "# fit model and predict clusters\n",
        "yhat = model.fit_predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "\t# get row indexes for samples with this cluster\n",
        "\trow_ix = where(yhat == cluster)\n",
        "\t# create scatter of these samples\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 3])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k0jbTB4m14By"
      },
      "source": [
        "\\\\\n",
        "Gaussian mixture clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X0vW-kHa1-Z-"
      },
      "source": [
        "# gaussian mixture clustering\n",
        "from numpy import unique\n",
        "from numpy import where\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from matplotlib import pyplot\n",
        "\n",
        "# define dataset\n",
        "X = quality_df_without_NaN.to_numpy()\n",
        "# define the model\n",
        "model = GaussianMixture(n_components=4)\n",
        "# fit the model\n",
        "model.fit(X)\n",
        "# assign a cluster to each example\n",
        "yhat = model.predict(X)\n",
        "# retrieve unique clusters\n",
        "clusters = unique(yhat)\n",
        "# create scatter plot for samples from each cluster\n",
        "for cluster in clusters:\n",
        "  # get row indexes for samples with this cluster\n",
        "  row_ix = where(yhat == cluster)\n",
        "  # create scatter of these samples\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 3])\n",
        "# show the plot\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aq_TnoXc2Rqp"
      },
      "source": [
        "\\\\\n",
        "### With NaN values\n",
        "\n",
        "Because most of the rows in our dataset have score, likes and dislikes value equal to NaN and also because we converted NaN values to value equal to 0, there was no enough RAM for calculations to form the desired clusters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6pd3WDF0w8S"
      },
      "source": [
        "#**Part 2 - clustering the amount of purchases of all pruducts in each city**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2AGNIJh4gWF"
      },
      "source": [
        "## **Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BD6iTcZY3Dzq"
      },
      "source": [
        "df_orders = pd.read_csv('orders.csv')\n",
        "df_orders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYMb3XBC690U"
      },
      "source": [
        "\\\\\n",
        "Describe the Amount_Gross_Order column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Iujo0Xl68_C"
      },
      "source": [
        "amount_gross_des = df_orders['Amount_Gross_Order'].describe()\n",
        "amount_gross_des"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bOxlyuNC7K4E"
      },
      "source": [
        "amount_gross_mean = amount_gross_des['mean']\n",
        "amount_gross_std  = amount_gross_des['std']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tF3N1PfE5vYO"
      },
      "source": [
        "\\\\\n",
        "Normalizing the Amout_Gross_Order values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2oc4gwM52Sy"
      },
      "source": [
        "df_orders['normalized_gross'] = df_orders.apply(lambda row: (row.Amount_Gross_Order - amount_gross_mean) / amount_gross_std, axis=1)\n",
        "\n",
        "df_orders"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oXXDvnZLp6z"
      },
      "source": [
        "\\\\\n",
        "In the cell below you can see the top 10 cities based on the total number of orders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wW9tQYcGD71"
      },
      "source": [
        "groupby_city = df_orders.groupby(by=['city_name_fa']).sum()\n",
        "sorted = groupby_city.sort_values(by=['Quantity_item'], ascending=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzDO20Ui4GFE"
      },
      "source": [
        "city_quantity = sorted.filter(['Quantity_item', 'normalized_gross'], axis=1)\n",
        "\n",
        "city_quantity"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ha2u-jFz4mUX"
      },
      "source": [
        "\\\\\n",
        "## **Clustering**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d77FIxGQOmj-"
      },
      "source": [
        "# agglomerative clustering\r\n",
        "from numpy import unique\r\n",
        "from numpy import where\r\n",
        "from sklearn.cluster import AgglomerativeClustering\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "# define dataset\r\n",
        "X = city_quantity.to_numpy()\r\n",
        "# define the model\r\n",
        "model = AgglomerativeClustering(n_clusters=3)\r\n",
        "# fit model and predict clusters\r\n",
        "yhat = model.fit_predict(X)\r\n",
        "# retrieve unique clusters\r\n",
        "clusters = unique(yhat)\r\n",
        "# create scatter plot for samples from each cluster\r\n",
        "for cluster in clusters:\r\n",
        "\t# get row indexes for samples with this cluster\r\n",
        "\trow_ix = where(yhat == cluster)\r\n",
        "\t# create scatter of these samples\r\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\r\n",
        "# show the plot\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sf6Dc0knLQBD"
      },
      "source": [
        "from numpy import unique\r\n",
        "from numpy import where\r\n",
        "from sklearn.cluster import DBSCAN\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "X = city_quantity.to_numpy()\r\n",
        "model = DBSCAN(eps=0.10, min_samples=12)\r\n",
        "yhat = model.fit_predict(X)\r\n",
        "clusters = unique(yhat)\r\n",
        "for cluster in clusters:\r\n",
        "\trow_ix = where(yhat == cluster)\r\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2wWI56DLkOo"
      },
      "source": [
        "# k-means clustering\r\n",
        "from numpy import unique\r\n",
        "from numpy import where\r\n",
        "from sklearn.cluster import KMeans\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "X = city_quantity.to_numpy()\r\n",
        "model = KMeans(n_clusters=4)\r\n",
        "model.fit(X)\r\n",
        "yhat = model.predict(X)\r\n",
        "clusters = unique(yhat)\r\n",
        "for cluster in clusters:\r\n",
        "\trow_ix = where(yhat == cluster)\r\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fPaG-Q_L1Ff"
      },
      "source": [
        "# mini-batch k-means clustering\r\n",
        "from numpy import unique\r\n",
        "from numpy import where\r\n",
        "from sklearn.cluster import MiniBatchKMeans\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "# define dataset\r\n",
        "X = city_quantity.to_numpy()\r\n",
        "# define the model\r\n",
        "model = MiniBatchKMeans(n_clusters=4)\r\n",
        "# fit the model\r\n",
        "model.fit(X)\r\n",
        "# assign a cluster to each example\r\n",
        "yhat = model.predict(X)\r\n",
        "# retrieve unique clusters\r\n",
        "clusters = unique(yhat)\r\n",
        "# create scatter plot for samples from each cluster\r\n",
        "for cluster in clusters:\r\n",
        "\t# get row indexes for samples with this cluster\r\n",
        "\trow_ix = where(yhat == cluster)\r\n",
        "\t# create scatter of these samples\r\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\r\n",
        "# show the plot\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COg4Fl4LL6XH"
      },
      "source": [
        "\r\n",
        "# mean shift clustering\r\n",
        "from numpy import unique\r\n",
        "from numpy import where\r\n",
        "from sklearn.cluster import MeanShift\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "# define dataset\r\n",
        "X = city_quantity.to_numpy()\r\n",
        "# define the model\r\n",
        "model = MeanShift()\r\n",
        "# fit model and predict clusters\r\n",
        "yhat = model.fit_predict(X)\r\n",
        "# retrieve unique clusters\r\n",
        "clusters = unique(yhat)\r\n",
        "# create scatter plot for samples from each cluster\r\n",
        "for cluster in clusters:\r\n",
        "\t# get row indexes for samples with this cluster\r\n",
        "\trow_ix = where(yhat == cluster)\r\n",
        "\t# create scatter of these samples\r\n",
        "\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1])\r\n",
        "# show the plot\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTYYq9RTMNo-"
      },
      "source": [
        "# gaussian mixture clustering\r\n",
        "from numpy import unique\r\n",
        "from numpy import where\r\n",
        "from sklearn.mixture import GaussianMixture\r\n",
        "from matplotlib import pyplot\r\n",
        "\r\n",
        "# define dataset\r\n",
        "X = city_quantity.to_numpy()\r\n",
        "# define the model\r\n",
        "model = GaussianMixture(n_components=4)\r\n",
        "# fit the model\r\n",
        "model.fit(X)\r\n",
        "# assign a cluster to each example\r\n",
        "yhat = model.predict(X)\r\n",
        "# retrieve unique clusters\r\n",
        "clusters = unique(yhat)\r\n",
        "# create scatter plot for samples from each cluster\r\n",
        "for cluster in clusters:\r\n",
        "  # get row indexes for samples with this cluster\r\n",
        "  row_ix = where(yhat == cluster)\r\n",
        "  # create scatter of these samples\r\n",
        "  pyplot.scatter(X[row_ix, 0], X[row_ix, 1])\r\n",
        "# show the plot\r\n",
        "pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}